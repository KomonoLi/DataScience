{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's a running history for the past week.\n",
    "# For each day, it contains whether or not the person ran, and whether or not they were tired.\n",
    "days = [[\"ran\", \"was tired\"], [\"ran\", \"was not tired\"], [\"didn't run\", \"was tired\"], [\"ran\", \"was tired\"], [\"didn't run\", \"was not tired\"], [\"ran\", \"was not tired\"], [\"ran\", \"was tired\"]]\n",
    "\n",
    "# Let's say we want to calculate the odds that someone was tired given that they ran, using bayes' theorem.\n",
    "# This is P(A).\n",
    "prob_tired = len([d for d in days if d[1] == \"was tired\"]) / len(days)\n",
    "# This is P(B).\n",
    "prob_ran = len([d for d in days if d[0] == \"ran\"]) / len(days)\n",
    "# This is P(B|A).\n",
    "prob_ran_given_tired = len([d for d in days if d[0] == \"ran\" and d[1] == \"was tired\"]) / len([d for d in days if d[1] == \"was tired\"])\n",
    "\n",
    "# Now we can calculate P(A|B).\n",
    "prob_tired_given_ran = (prob_ran_given_tired * prob_tired) / prob_ran\n",
    "\n",
    "print(\"Probability of being tired given that you ran: {0}\".format(prob_tired_given_ran))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Here's our data, but with \"woke up early\" or \"didn't wake up early\" added.\n",
    "days = [[\"ran\", \"was tired\", \"woke up early\"], [\"ran\", \"was not tired\", \"didn't wake up early\"], \n",
    "        [\"didn't run\", \"was tired\", \"woke up early\"], [\"ran\", \"was tired\", \"didn't wake up early\"], [\"didn't run\", \"was tired\", \"woke up early\"], [\"ran\", \"was not tired\", \"didn't wake up early\"], [\"ran\", \"was tired\", \"woke up early\"]]\n",
    "\n",
    "# We're trying to predict whether or not the person was tired on this day.\n",
    "new_day = [\"ran\", \"didn't wake up early\"]\n",
    "\n",
    "def calc_y_probability(y_label, days):\n",
    "    return len([d for d in days if d[1] == y_label]) / len(days)\n",
    "\n",
    "def calc_ran_probability_given_y(ran_label, y_label, days):\n",
    "    return len([d for d in days if d[1] == y_label and d[0] == ran_label]) / len(days)\n",
    "\n",
    "def calc_woke_early_probability_given_y(woke_label, y_label, days):\n",
    "    return len([d for d in days if d[1] == y_label and d[2] == woke_label]) / len(days)\n",
    "\n",
    "denominator = len([d for d in days if d[0] == new_day[0] and d[2] == new_day[1]]) / len(days)\n",
    "# Plug all the values into our formula.  Multiply the class (y) probability, and the probability of the x-values occuring given that class.\n",
    "prob_tired = (calc_y_probability(\"was tired\", days) * calc_ran_probability_given_y(new_day[0], \"was tired\", days) * calc_woke_early_probability_given_y(new_day[1], \"was tired\", days)) / denominator\n",
    "\n",
    "prob_not_tired = (calc_y_probability(\"was not tired\", days) * calc_ran_probability_given_y(new_day[0], \"was not tired\", days) * calc_woke_early_probability_given_y(new_day[1], \"was not tired\", days)) / denominator\n",
    "\n",
    "# Make a classification decision based on the probabilities.\n",
    "classification = \"was tired\"\n",
    "if prob_not_tired > prob_tired:\n",
    "    classification = \"was not tired\"\n",
    "print(\"Final classification for new day: {0}. Tired probability: {1}. Not tired probability: {2}.\".format(classification, prob_tired, prob_not_tired))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# A nice python class that lets you count how many times items occur in a list\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Read in the training data.\n",
    "with open(\"train.csv\", 'r') as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "\n",
    "def get_text(reviews, score):\n",
    "    # Join together the text in the reviews for a particular tone.\n",
    "    # We lowercase to avoid \"Not\" and \"not\" being seen as different words, for example.\n",
    "    return \" \".join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "\n",
    "def count_text(text):\n",
    "    # Split text into words based on whitespace.  Simple but effective.\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    # Count up the occurence of each word.\n",
    "    return Counter(words)\n",
    "\n",
    "negative_text = get_text(reviews, -1)\n",
    "positive_text = get_text(reviews, 1)\n",
    "# Generate word counts for negative tone.\n",
    "negative_counts = count_text(negative_text)\n",
    "# Generate word counts for positive tone.\n",
    "positive_counts = count_text(positive_text)\n",
    "\n",
    "print(\"Negative text sample: {0}\".format(negative_text[:100]))\n",
    "print(\"Positive text sample: {0}\".format(positive_text[:100]))\n",
    "\n",
    "#print(negative_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_y_count(score):\n",
    "    # Compute the count of each classification occuring in the data.\n",
    "    return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "# We need these counts to use for smoothing when computing the prediction.\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "\n",
    "# These are the class probabilities (we saw them in the formula as P(y)).\n",
    "prob_positive = positive_review_count / len(reviews)\n",
    "prob_negative = negative_review_count / len(reviews)\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    for word in text_counts:\n",
    "        # For every word in the text, we get the number of times that word occured in the reviews for a given class, add 1 to smooth the value, and divide by the total number of words in the class (plus the class_count to also smooth the denominator).\n",
    "        # Smoothing ensures that we don't multiply the prediction by 0 if the word didn't exist in the training data.\n",
    "        # We also smooth the denominator counts to keep things even.\n",
    "        prediction *=  text_counts.get(word) * ((counts.get(word, 0) + 1) / (sum(counts.values()) + class_count))\n",
    "    # Now we multiply by the probability of the class existing in the documents.\n",
    "    return prediction * class_prob\n",
    "\n",
    "# As you can see, we can now generate probabilities for which class a given review is part ofa.\n",
    "# The probabilities themselves aren't very useful -- we make our classification decision based on which value is greater.\n",
    "print(\"Review: {0}\".format(reviews[0][0]))\n",
    "print(\"Negative prediction: {0}\".format(make_class_prediction(reviews[0][0], negative_counts, prob_negative, negative_review_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(reviews[0][0], positive_counts, prob_positive, positive_review_count)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities.\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)\n",
    "\n",
    "    # We assign a classification based on which probability is greater.\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return -1\n",
    "    return 1\n",
    "\n",
    "with open(\"test.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "actual = [int(r[1]) for r in test]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate the roc curve using scikits-learn.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve.  The closer to 1, the \"better\" the predictions.\n",
    "print(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate counts from text using a vectorizer.  There are other vectorizers available, and lots of options you can set.\n",
    "# This performs our step of computing word counts.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a naive bayes model to the training data.\n",
    "# This will train the model using the word counts we computer, and the existing classifications in the training set.\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features.\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error.  It is slightly different from our model because the internals of this process work differently from our implementation.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "print(\"Multinomal naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
