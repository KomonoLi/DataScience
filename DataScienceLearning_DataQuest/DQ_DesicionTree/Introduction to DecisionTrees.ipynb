{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# Set index_col to False to avoid pandas thinking that the first column is row indexes (it's age).\n",
    "income = pandas.read_csv(\"income.csv\", index_col=False)\n",
    "print(income.head(5))\n",
    "\n",
    "# Convert a single column from text categories into numbers.\n",
    "col = pandas.Categorical.from_array(income[\"workclass\"])\n",
    "income[\"workclass\"] = col.codes\n",
    "print(income[\"workclass\"].head(5))\n",
    "\n",
    "for name in ['education','marital_status','occupation','relationship','race','sex','native_country','high_income']:\n",
    "    income[name] = pandas.Categorical.from_array(income[name]).codes\n",
    "    \n",
    "\n",
    "    \n",
    "# Enter your code here.\n",
    "private_incomes = income[income['workclass'] == 4]\n",
    "public_incomes = income[income['workclass'] != 4]\n",
    "\n",
    "\n",
    "print(private_incomes.shape)\n",
    "print(public_incomes.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "# We'll do the same calculation we did above, but in Python.\n",
    "# Passing 2 as the second parameter to math.log will take a base 2 log.\n",
    "entropy = -(2/5 * math.log(2/5, 2) + 3/5 * math.log(3/5, 2))\n",
    "print(entropy)\n",
    "\n",
    "prob_0 = income[income['high_income'] == 0]. shape[0]/income.shape[0]\n",
    "\n",
    "prob_1 = income[income[\"high_income\"] == 1].shape[0] / income.shape[0]\n",
    "\n",
    "income_entropy = -(prob_0 * math.log(prob_0, 2) + prob_1 * math.log(prob_1, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas Series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column.\n",
    "    counts = numpy.bincount(column)\n",
    "    # Divide by the total column length to get a probability.\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0.\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy.\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy\n",
    "\n",
    "# Verify our function matches our answer from earlier.\n",
    "entropy = calc_entropy([1,1,0,0,1])\n",
    "print(entropy)\n",
    "\n",
    "information_gain = entropy - ((.8 * calc_entropy([1,1,0,0])) + (.2 * calc_entropy([1])))\n",
    "print(information_gain)\n",
    "\n",
    "income_entropy = calc_entropy(income['high_income'])\n",
    "median = income['age'].median()\n",
    "\n",
    "left_split = income[income['age'] <= median]\n",
    "right_split = income[income['age'] > median]\n",
    "\n",
    "age_information_gain = income_entropy - ((left_split.shape[0] / income.shape[0]) * calc_entropy(left_split[\"high_income\"]) + ((right_split.shape[0] / income.shape[0]) * calc_entropy(right_split[\"high_income\"])))\n",
    "\n",
    "print(age_information_gain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a dataset, column to split on, and target.\n",
    "    \"\"\"\n",
    "    # Calculate original entropy.\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Find the median of the column we're splitting.\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    # Make two subsets of the data based on the median.\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    # Loop through the splits, and calculate the subset entropy.\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain.\n",
    "    return original_entropy - to_subtract\n",
    "\n",
    "# Verify that our answer is the same as in the last screen.\n",
    "print(calc_information_gain(income, \"age\", \"high_income\"))\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "information_gains = []\n",
    "\n",
    "for col in columns:\n",
    "    information_gain = calc_information_gain(income, col, \"high_income\")\n",
    "    information_gains.append(information_gain)\n",
    "\n",
    "# Find the name of the column with the highest gain.\n",
    "highest_gain_index = information_gains.index(max(information_gains))\n",
    "highest_gain = columns[highest_gain_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
